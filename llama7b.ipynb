{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peppertaco/AI/blob/main/llama7b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#우바부가 API + SillyLossy 확장기능 모딩 태번"
      ],
      "metadata": {
        "id": "SbuwKBalZvFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "#Taken from KoboldAI colab\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start TavernAI below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://henk.tech/colabkobold/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "ZScVU8a6ZuXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peng-woXZsh5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color = \"red\">TavernAI</b>\n",
        "#@markdown <font color = \"red\"><-- 눌러 (≖ ‸ ≖ ✿)\n",
        "\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "extras_enable_captioning = True #@param {type:\"boolean\"}\n",
        "Captions_Model = \"Salesforce/blip-image-captioning-large\" #@param [ \"Salesforce/blip-image-captioning-large\", \"Salesforce/blip-image-captioning-base\" ]\n",
        "#@markdown * Salesforce/blip-image-captioning-large - good base model\n",
        "#@markdown * Salesforce/blip-image-captioning-base - slightly faster but less accurate\n",
        "extras_enable_emotions = True #@param {type:\"boolean\"}\n",
        "Emotions_Model = \"bhadresh-savani/distilbert-base-uncased-emotion\" #@param [\"bhadresh-savani/distilbert-base-uncased-emotion\", \"joeddav/distilbert-base-uncased-go-emotions-student\"]\n",
        "#@markdown * bhadresh-savani/distilbert-base-uncased-emotion = 6 supported emotions<br>\n",
        "#@markdown * joeddav/distilbert-base-uncased-go-emotions-student = 28 supported emotions\n",
        "extras_enable_memory = True #@param {type:\"boolean\"}\n",
        "Memory_Model = \"Qiliang/bart-large-cnn-samsum-ChatGPT_v3\" #@param [ \"Qiliang/bart-large-cnn-samsum-ChatGPT_v3\", \"Qiliang/bart-large-cnn-samsum-ElectrifAi_v10\", \"distilbart-xsum-12-3\" ]\n",
        "#@markdown * Qiliang/bart-large-cnn-samsum-ChatGPT_v3 - summarization model optimized for chats\n",
        "#@markdown * Qiliang/bart-large-cnn-samsum-ElectrifAi_v10 - nice results so far, but still being evaluated\n",
        "#@markdown * distilbart-xsum-12-3 - faster, but pretty basic alternative\n",
        "\n",
        "!nvidia-smi\n",
        "!npm install -g localtunnel\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import threading\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "    \n",
        "if use_google_drive:\n",
        "  drive.mount('/content/drive/')\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/characters/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/characters/\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/chats/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/chats/\")\n",
        "else:\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    os.mkdir(\"/content/drive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/\")\n",
        "\n",
        "def copy_characters(use_google_drive=False):\n",
        "  if not use_google_drive:\n",
        "    return\n",
        "  \n",
        "  src_folder = \"/TavernAI/public/characters\"\n",
        "  dst_folder = \"/content/drive/MyDrive/TavernAI/characters\"\n",
        "\n",
        "  for filename in os.listdir(src_folder):\n",
        "    src_file = os.path.join(src_folder, filename)\n",
        "    dst_file = os.path.join(dst_folder, filename)\n",
        "\n",
        "    if os.path.exists(dst_file):\n",
        "      print(f\"{dst_file} already exists. Skipping...\")\n",
        "      continue\n",
        "\n",
        "    shutil.copy(src_file, dst_folder)\n",
        "    print(f\"{src_file} copied to {dst_folder}\")\n",
        "\n",
        "\n",
        "# 우가우가\n",
        "\n",
        "!pip uninstall transformers\n",
        "!pip install git+https://github.com/zphang/transformers.git@68d640f7c368bcaaaecfc678f11908ebbd3d6176\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "!mkdir text-generation-webui/logs\n",
        "\n",
        "!ln -s text-generation-webui/logs .\n",
        "!ln -s text-generation-webui/characters .\n",
        "!ln -s text-generation-webui/models .\n",
        "%cd text-generation-webui\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/text-generation-webui/\n",
        "!mkdir repositories\n",
        "%cd /content/text-generation-webui/repositories/\n",
        "!git clone https://github.com/qwopqwop200/GPTQ-for-LLaMa\n",
        "%cd GPTQ-for-LLaMa\n",
        "!python setup_cuda.py install\n",
        "%cd /content/text-generation-webui/\n",
        "!python download-model.py --text-only decapoda-research/llama-7b-hf\n",
        "!wget -nc https://huggingface.co/decapoda-research/llama-7b-hf-int4/resolve/main/llama-7b-4bit.pt -P /content/models/llama-7b-hf/\n",
        "os.remove(\"/content/models/llama-7b-hf/tokenizer_config.json\")\n",
        "!git clone https://github.com/peppertaco/token\n",
        "shutil.copy(\"/content/text-generation-webui/token/tokenizer_config.json\",\"/content/models/llama-7b-hf/tokenizer_config.json\")\n",
        "shutil.rmtree(\"/content/text-generation-webui/token\")\n",
        "!nohup python server.py --notebook --no-stream --share --model llama-7b-hf --gptq-bits 4 &\n",
        "\n",
        "params = []\n",
        "\n",
        "params.append('--cpu')\n",
        "\n",
        "ExtrasModules = []\n",
        "\n",
        "if (extras_enable_captioning):\n",
        "  ExtrasModules.append('caption')\n",
        "\n",
        "if (extras_enable_memory):\n",
        "  ExtrasModules.append('summarize')\n",
        "\n",
        "if (extras_enable_emotions):\n",
        "  ExtrasModules.append('classify')\n",
        "\n",
        "params.append(f'--classification-model={Emotions_Model}')\n",
        "params.append(f'--summarization-model={Memory_Model}')\n",
        "params.append(f'--captioning-model={Captions_Model}')\n",
        "params.append(f'--enable-modules={\",\".join(ExtrasModules)}')\n",
        "\n",
        "#TavernAI extras\n",
        "%cd /\n",
        "!git clone https://github.com/SillyLossy/TavernAI-extras\n",
        "%cd TavernAI-extras\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorflow==2.11\n",
        "cmd = f\"python server.py {' '.join(params)}\"\n",
        "print(cmd)\n",
        "\n",
        "extras_process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd='/TavernAI-extras', shell=True)\n",
        "print('processId:', extras_process.pid)\n",
        "\n",
        "while True:\n",
        "    line = extras_process.stdout.readline().decode().strip()\n",
        "    if \"Running on \" in line:\n",
        "        break\n",
        "    if not line:\n",
        "        print('breaking on line')\n",
        "        break\n",
        "    print(line)\n",
        "\n",
        "subprocess.call('nohup lt --port 5100 > ./extras.out 2> ./extras.err &', shell=True)\n",
        "print('Waiting for lt init...')\n",
        "time.sleep(5)\n",
        "\n",
        "while True:\n",
        "  if (os.path.getsize('./extras.out') > 0):\n",
        "    with open('./extras.out', 'r') as f:\n",
        "      lines = f.readlines()\n",
        "      for x in range(len(lines)):\n",
        "        if ('your url is: ' in lines[x]):\n",
        "          print('TavernAI Extensions URL:')\n",
        "          extras_url = lines[x].split('your url is: ')[1]\n",
        "          print(extras_url)\n",
        "      break\n",
        "  if (os.path.getsize('./extras.err') > 0):\n",
        "    with open('./extras.err', 'r') as f:\n",
        "      print(f.readlines())\n",
        "      break\n",
        "\n",
        "#TavernAI\n",
        "%cd /\n",
        "!curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.2/install.sh | bash\n",
        "!nvm install 19.1.0\n",
        "!nvm use 19.1.0\n",
        "!node -v\n",
        "!git clone -b dev https://github.com/SillyLossy/TavernAI\n",
        "copy_characters(use_google_drive)\n",
        "%cd TavernAI\n",
        "!npm install\n",
        "time.sleep(1)\n",
        "%env colab=2\n",
        "%env colaburl=$url\n",
        "if use_google_drive:\n",
        "  %env googledrive=2\n",
        "!nohup node server.js &\n",
        "time.sleep(3)\n",
        "print('###oobabooga API###')\n",
        "lt_process = subprocess.Popen(['lt', '--port', '7860'], stdout=subprocess.PIPE)\n",
        "line = lt_process.stdout.readline()\n",
        "print(line.decode().strip())\n",
        "print('### TavernAI Extensions LINK ###')\n",
        "print(extras_url)\n",
        "print('')\n",
        "print('###TavernAI LINK###')\n",
        "lt_process2 = subprocess.Popen(['lt', '--port', '8000'], stdout=subprocess.PIPE)\n",
        "line = lt_process2.stdout.readline()\n",
        "print(line.decode().strip())"
      ]
    }
  ]
}